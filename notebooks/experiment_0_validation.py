# -*- coding: utf-8 -*-
"""experiment_0_validation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18tD76P0b0Y5hyB0Eye1YOAPIud76uSoQ
"""

# Commented out IPython magic to ensure Python compatibility.
"""
EXPERIMENT 0: Direction Validation
===================================
Goal: Verify that refusal directions actually separate harmful/harmless prompts

Steps:
1. Load harmful and harmless datasets
2. Compute direction at each layer: harmful_mean - harmless_mean
3. Test statistical separation (t-test, Cohen's d)
4. Identify valid layers
"""

# Mount Drive
from google.colab import drive
drive.mount('/content/drive')

# Navigate
# %cd /content/drive/MyDrive/LLM-refusal-directions-and-preferences

# Add to path
import sys
sys.path.append('/content/drive/MyDrive/LLM-refusal-directions-and-preferences')

print("✓ Setup complete")

# Install requirements
!pip install -q -r requirements.txt

# Imports
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
from scipy.stats import ttest_ind
import matplotlib.pyplot as plt
from tqdm import tqdm

print("✓ All imports successful")
print(f"✓ CUDA available: {torch.cuda.is_available()}")

# Load model
model_name = "Qwen/Qwen2.5-1.5B-Instruct"
print(f"Loading {model_name}...")

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)

n_layers = len(model.model.layers)
hidden_size = model.config.hidden_size

print(f"✓ Model loaded")
print(f"✓ Layers: {n_layers}")
print(f"✓ Hidden size: {hidden_size}")

# Load harmful and harmless datasets
print("Loading datasets...")

harmful_ds = load_dataset('mlabonne/harmful_behaviors')
harmful_prompts = harmful_ds['train']['text'][:256]

harmless_ds = load_dataset('mlabonne/harmless_alpaca')
harmless_prompts = harmless_ds['train']['text'][:256]

print(f"✓ Loaded {len(harmful_prompts)} harmful prompts")
print(f"✓ Loaded {len(harmless_prompts)} harmless prompts")

# Show examples
print("\n" + "="*60)
print("EXAMPLES:")
print("="*60)
print(f"\nHarmful example 1: {harmful_prompts[0][:80]}...")
print(f"Harmful example 2: {harmful_prompts[1][:80]}...")
print(f"\nHarmless example 1: {harmless_prompts[0][:80]}...")
print(f"Harmless example 2: {harmless_prompts[1][:80]}...")

def get_activation(prompt, model, tokenizer, layer_idx):
    """
    Extract activation at last token position for a specific layer

    Args:
        prompt: text string
        layer_idx: which layer (0 to n_layers-1)

    Returns:
        numpy array of shape (hidden_size,)
    """
    # Format prompt
    messages = [{"role": "user", "content": prompt}]
    formatted = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )

    # Tokenize
    inputs = tokenizer(
        formatted,
        return_tensors="pt",
        truncation=True,
        max_length=512
    ).to(model.device)

    # Get activations
    with torch.no_grad():
        outputs = model(**inputs, output_hidden_states=True)

    # Extract last token position, specific layer
    last_pos = inputs['input_ids'].shape[1] - 1
    activation = outputs.hidden_states[layer_idx + 1][0, last_pos, :].cpu().numpy()

    return activation

# Test it
test_activation = get_activation("Hello", model, tokenizer, layer_idx=15)
print(f"✓ Function works!")
print(f"✓ Activation shape: {test_activation.shape}")
print(f"✓ Mean: {test_activation.mean():.4f}")

print("="*60)
print("COMPUTING REFUSAL DIRECTIONS FOR ALL LAYERS")
print("="*60)
print(f"This will process {len(harmful_prompts)} harmful + {len(harmless_prompts)} harmless prompts")
print(f"Across {n_layers} layers")
print(f"Estimated time: 10-15 minutes\n")

all_directions = []

for layer_idx in range(n_layers):
    print(f"Processing layer {layer_idx}/{n_layers-1}...", end=" ")

    # Collect activations for this layer
    harmful_acts = []
    harmless_acts = []

    # Harmful prompts
    for prompt in tqdm(harmful_prompts, desc=f"Layer {layer_idx} harmful", leave=False):
        act = get_activation(prompt, model, tokenizer, layer_idx)
        harmful_acts.append(act)

    # Harmless prompts
    for prompt in tqdm(harmless_prompts, desc=f"Layer {layer_idx} harmless", leave=False):
        act = get_activation(prompt, model, tokenizer, layer_idx)
        harmless_acts.append(act)

    # Compute direction: harmful_mean - harmless_mean
    harmful_mean = np.array(harmful_acts).mean(axis=0)
    harmless_mean = np.array(harmless_acts).mean(axis=0)
    direction = harmful_mean - harmless_mean

    # Normalize
    direction_norm = direction / np.linalg.norm(direction)
    magnitude = np.linalg.norm(direction)

    all_directions.append({
        'layer': layer_idx,
        'direction': direction_norm,
        'magnitude': magnitude,
        'harmful_acts': harmful_acts,
        'harmless_acts': harmless_acts
    })

    print(f"✓ magnitude: {magnitude:.3f}")

print(f"\n✓ Computed directions for all {n_layers} layers")

print("="*60)
print("STATISTICAL VALIDATION")
print("="*60)
print("Testing if directions actually separate harmful/harmless\n")

validation_results = []

for dir_info in all_directions:
    layer = dir_info['layer']
    direction = dir_info['direction']
    harmful_acts = dir_info['harmful_acts']
    harmless_acts = dir_info['harmless_acts']

    # Project all activations onto the direction
    harmful_projections = [np.dot(act, direction) for act in harmful_acts]
    harmless_projections = [np.dot(act, direction) for act in harmless_acts]

    # Statistical test: are these distributions different?
    t_stat, p_val = ttest_ind(harmful_projections, harmless_projections)

    # Effect size (Cohen's d)
    mean_diff = np.mean(harmful_projections) - np.mean(harmless_projections)
    pooled_std = np.sqrt(
        (np.std(harmful_projections)**2 + np.std(harmless_projections)**2) / 2
    )
    cohens_d = mean_diff / pooled_std if pooled_std > 0 else 0

    validation_results.append({
        'layer': layer,
        'magnitude': dir_info['magnitude'],
        'harmful_mean_proj': np.mean(harmful_projections),
        'harmless_mean_proj': np.mean(harmless_projections),
        't_statistic': t_stat,
        'p_value': p_val,
        'cohens_d': cohens_d,
        'valid': p_val < 0.01 and abs(cohens_d) > 0.5  # Strong effect
    })

# Summary
valid_layers = [r for r in validation_results if r['valid']]
print(f"\n✓ Valid directions: {len(valid_layers)}/{n_layers}")
print(f"\nTop 10 strongest separations:")
print(f"{'Layer':<8}{'Magnitude':<12}{'Cohen\'s d':<12}{'p-value':<12}{'Valid?':<8}")
print("-"*60)

sorted_results = sorted(validation_results, key=lambda x: abs(x['cohens_d']), reverse=True)
for r in sorted_results[:10]:
    valid_mark = "✓" if r['valid'] else "✗"
    print(f"{r['layer']:<8}{r['magnitude']:<12.2f}{r['cohens_d']:<12.2f}{r['p_value']:<12.2e}{valid_mark:<8}")

# Visualize all layers
fig, axes = plt.subplots(1, 3, figsize=(15, 4))

layers = [r['layer'] for r in validation_results]
magnitudes = [r['magnitude'] for r in validation_results]
cohens_d = [r['cohens_d'] for r in validation_results]
p_values = [-np.log10(r['p_value']) if r['p_value'] > 0 else 350 for r in validation_results]

# Plot 1: Magnitude by layer
axes[0].plot(layers, magnitudes, 'o-', linewidth=2)
axes[0].set_xlabel('Layer')
axes[0].set_ylabel('Direction Magnitude')
axes[0].set_title('Separation Distance')
axes[0].grid(True, alpha=0.3)

# Plot 2: Cohen's d by layer
axes[1].plot(layers, cohens_d, 'o-', linewidth=2, color='orange')
axes[1].axhline(y=0.5, color='r', linestyle='--', label='Threshold (d=0.5)')
axes[1].set_xlabel('Layer')
axes[1].set_ylabel("Cohen's d")
axes[1].set_title('Effect Size')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

# Plot 3: -log10(p-value) by layer
axes[2].plot(layers, p_values, 'o-', linewidth=2, color='green')
axes[2].axhline(y=-np.log10(0.01), color='r', linestyle='--', label='p=0.01')
axes[2].set_xlabel('Layer')
axes[2].set_ylabel('-log10(p-value)')
axes[2].set_title('Statistical Significance')
axes[2].legend()
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('results/validation/layer_analysis.png', dpi=300, bbox_inches='tight')
print("✓ Saved: results/validation/layer_analysis.png")
plt.show()

# Show all layers
print("\n" + "="*60)
print("ALL LAYERS:")
print("="*60)
print(f"{'Layer':<8}{'Magnitude':<12}{'Cohen\'s d':<12}{'p-value':<12}{'Valid?':<8}")
print("-"*60)
for r in validation_results:
    valid_mark = "✓" if r['valid'] else "✗"
    print(f"{r['layer']:<8}{r['magnitude']:<12.2f}{r['cohens_d']:<12.2f}{r['p_value']:<12.2e}{valid_mark:<8}")

# Save the validated directions
import pickle

save_data = {
    'model_name': model_name,
    'n_layers': n_layers,
    'directions': all_directions,
    'validation_results': validation_results
}

with open('data/directions/validated_directions.pkl', 'wb') as f:
    pickle.dump(save_data, f)

print("✓ Saved validated directions to: data/directions/validated_directions.pkl")
print(f"\nSummary:")
print(f"  Valid layers: {len(valid_layers)}/{n_layers}")
print(f"  Strongest layer: {sorted_results[0]['layer']} (Cohen's d = {sorted_results[0]['cohens_d']:.2f})")
print(f"  Peak magnitude: Layer {max(validation_results, key=lambda x: x['magnitude'])['layer']}")

import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 3, figsize=(15, 4))

layers = [r['layer'] for r in validation_results]
magnitudes = [r['magnitude'] for r in validation_results]
cohens_d = [r['cohens_d'] for r in validation_results]

# Plot 1: Magnitude
axes[0].plot(layers, magnitudes, 'o-', linewidth=2, markersize=4)
axes[0].set_xlabel('Layer', fontsize=12)
axes[0].set_ylabel('Direction Magnitude', fontsize=12)
axes[0].set_title('Separation Distance by Layer', fontsize=13)
axes[0].grid(True, alpha=0.3)

# Plot 2: Cohen's d
axes[1].plot(layers, cohens_d, 'o-', linewidth=2, markersize=4, color='orange')
axes[1].axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='Threshold')
axes[1].set_xlabel('Layer', fontsize=12)
axes[1].set_ylabel("Cohen's d (Effect Size)", fontsize=12)
axes[1].set_title('Statistical Effect Size by Layer', fontsize=13)
axes[1].legend()
axes[1].grid(True, alpha=0.3)

# Plot 3: Both together
ax3 = axes[2]
ax3_twin = ax3.twinx()
ax3.plot(layers, cohens_d, 'o-', linewidth=2, color='orange', label="Cohen's d")
ax3_twin.plot(layers, magnitudes, 's-', linewidth=2, color='blue', alpha=0.6, label='Magnitude')
ax3.set_xlabel('Layer', fontsize=12)
ax3.set_ylabel("Cohen's d", fontsize=12, color='orange')
ax3_twin.set_ylabel('Magnitude', fontsize=12, color='blue')
ax3.set_title('Combined View', fontsize=13)
ax3.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from scipy import stats

print("="*60)
print("INTERNAL RANKING ANALYSIS")
print("="*60)

# We already have this data from our validation!
# Extract projections from layer 18 (strongest layer)
layer_18_data = [d for d in all_directions if d['layer'] == 18][0]
direction_18 = layer_18_data['direction']
harmful_acts = layer_18_data['harmful_acts']
harmless_acts = layer_18_data['harmless_acts']

# Compute projections
harmful_proj = [np.dot(act, direction_18) for act in harmful_acts]
harmless_proj = [np.dot(act, direction_18) for act in harmless_acts]

# Statistics
print(f"\n{'Category':<15}{'Mean':<12}{'Std':<12}{'Min':<12}{'Max':<12}{'Range':<12}")
print("-"*70)

harm_mean, harm_std = np.mean(harmful_proj), np.std(harmful_proj)
harm_min, harm_max = np.min(harmful_proj), np.max(harmful_proj)
print(f"{'Harmful':<15}{harm_mean:<12.3f}{harm_std:<12.3f}{harm_min:<12.3f}{harm_max:<12.3f}{harm_max-harm_min:<12.3f}")

harmless_mean, harmless_std = np.mean(harmless_proj), np.std(harmless_proj)
harmless_min, harmless_max = np.min(harmless_proj), np.max(harmless_proj)
print(f"{'Harmless':<15}{harmless_mean:<12.3f}{harmless_std:<12.3f}{harmless_min:<12.3f}{harmless_max:<12.3f}{harmless_max-harmless_min:<12.3f}")

# Key metric: Coefficient of variation (std relative to range)
harm_cv = harm_std / (harm_max - harm_min) if (harm_max - harm_min) > 0 else 0
harmless_cv = harmless_std / (harmless_max - harmless_min) if (harmless_max - harmless_min) > 0 else 0

print(f"\nCoefficient of Variation (std/range):")
print(f"  Harmful: {harm_cv:.3f}")
print(f"  Harmless: {harmless_cv:.3f}")
print(f"\nInterpretation:")
if harm_std > 1.5:
    print(f"  ✓ Harmful prompts show SUBSTANTIAL variance (std={harm_std:.2f})")
    print(f"    → Model likely has internal gradient, not binary classification")
else:
    print(f"  ✗ Harmful prompts tightly clustered (std={harm_std:.2f})")
    print(f"    → Model may treat all harmful prompts similarly")

# Visualize distributions
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Plot 1: Histograms
ax1 = axes[0, 0]
ax1.hist(harmful_proj, bins=30, alpha=0.6, color='red', label='Harmful', density=True)
ax1.hist(harmless_proj, bins=30, alpha=0.6, color='blue', label='Harmless', density=True)
ax1.axvline(harm_mean, color='red', linestyle='--', linewidth=2, label=f'Harmful mean={harm_mean:.1f}')
ax1.axvline(harmless_mean, color='blue', linestyle='--', linewidth=2, label=f'Harmless mean={harmless_mean:.1f}')
ax1.set_xlabel('Projection onto Refusal Direction', fontsize=11)
ax1.set_ylabel('Density', fontsize=11)
ax1.set_title('Distribution of Projections (Layer 18)', fontsize=12, fontweight='bold')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Plot 2: Cumulative distributions
ax2 = axes[0, 1]
sorted_harm = np.sort(harmful_proj)
sorted_harmless = np.sort(harmless_proj)
ax2.plot(sorted_harm, np.linspace(0, 1, len(sorted_harm)), 'r-', linewidth=2, label='Harmful')
ax2.plot(sorted_harmless, np.linspace(0, 1, len(sorted_harmless)), 'b-', linewidth=2, label='Harmless')
ax2.set_xlabel('Projection Value', fontsize=11)
ax2.set_ylabel('Cumulative Probability', fontsize=11)
ax2.set_title('Cumulative Distribution Functions', fontsize=12, fontweight='bold')
ax2.legend()
ax2.grid(True, alpha=0.3)

# Plot 3: Box plots
ax3 = axes[1, 0]
bp = ax3.boxplot([harmless_proj, harmful_proj],
                  labels=['Harmless', 'Harmful'],
                  patch_artist=True,
                  widths=0.6)
bp['boxes'][0].set_facecolor('blue')
bp['boxes'][1].set_facecolor('red')
for element in ['whiskers', 'fliers', 'means', 'medians', 'caps']:
    plt.setp(bp[element], color='black')
ax3.set_ylabel('Projection Value', fontsize=11)
ax3.set_title('Distribution Comparison (Box Plot)', fontsize=12, fontweight='bold')
ax3.grid(True, alpha=0.3, axis='y')

# Plot 4: Scatter showing spread
ax4 = axes[1, 1]
ax4.scatter(range(len(harmless_proj)), sorted(harmless_proj),
           alpha=0.5, s=20, color='blue', label='Harmless')
ax4.scatter(range(len(harmful_proj)), sorted(harmful_proj),
           alpha=0.5, s=20, color='red', label='Harmful')
ax4.set_xlabel('Sample Index (sorted)', fontsize=11)
ax4.set_ylabel('Projection Value', fontsize=11)
ax4.set_title('Sorted Projections Showing Variance', fontsize=12, fontweight='bold')
ax4.axhline(y=harm_mean, color='red', linestyle='--', alpha=0.5)
ax4.axhline(y=harmless_mean, color='blue', linestyle='--', alpha=0.5)
ax4.legend()
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('results/validation/projection_distributions.png', dpi=300, bbox_inches='tight')
print("\n✓ Saved: results/validation/projection_distributions.png")
plt.show()

print("="*60)
print("VARIANCE ANALYSIS ACROSS ALL LAYERS")
print("="*60)

# Analyze ALL layers
layer_analysis = []

for layer_data in tqdm(all_directions, desc="Analyzing layers"):
    layer = layer_data['layer']
    direction = layer_data['direction']
    harmful_acts = layer_data['harmful_acts']
    harmless_acts = layer_data['harmless_acts']

    # Compute projections
    harmful_proj = [np.dot(act, direction) for act in harmful_acts]
    harmless_proj = [np.dot(act, direction) for act in harmless_acts]

    # Full statistics
    layer_analysis.append({
        'layer': layer,
        'harmful_mean': np.mean(harmful_proj),
        'harmful_std': np.std(harmful_proj),
        'harmful_min': np.min(harmful_proj),
        'harmful_max': np.max(harmful_proj),
        'harmful_range': np.max(harmful_proj) - np.min(harmful_proj),
        'harmless_mean': np.mean(harmless_proj),
        'harmless_std': np.std(harmless_proj),
        'harmless_min': np.min(harmless_proj),
        'harmless_max': np.max(harmless_proj),
        'harmless_range': np.max(harmless_proj) - np.min(harmless_proj),
        'mean_separation': np.mean(harmful_proj) - np.mean(harmless_proj),
        'overlap_count': len([p for p in harmful_proj if p < np.mean(harmless_proj)]) +
                        len([p for p in harmless_proj if p > np.mean(harmful_proj)])
    })

# Save complete data
import pandas as pd
df_variance = pd.DataFrame(layer_analysis)
df_variance.to_csv('results/validation/variance_by_layer.csv', index=False)

print(f"\n✓ Saved complete analysis for ALL {len(layer_analysis)} layers")
print(f"✓ File: results/validation/variance_by_layer.csv")
print(f"\nColumns saved:")
for col in df_variance.columns:
    print(f"  - {col}")

# Preview first and last few rows
print("\nFirst 5 layers:")
print(df_variance.head().to_string())

print("\nLast 5 layers:")
print(df_variance.tail().to_string())

print("Creating multi-layer comparison figure...")

# Select representative layers
key_layers = [0, 5, 9, 12, 15, 18, 21, 27]

fig, axes = plt.subplots(2, 4, figsize=(20, 10))
fig.suptitle('Projection Distributions Across Key Layers - Progressive Build-Up',
             fontsize=18, fontweight='bold')

for idx, layer_num in enumerate(key_layers):
    row = idx // 4
    col = idx % 4
    ax = axes[row, col]

    # Get data for this layer
    layer_data = all_directions[layer_num]
    direction = layer_data['direction']
    harmful_acts = layer_data['harmful_acts']
    harmless_acts = layer_data['harmless_acts']

    # Compute projections
    harmful_proj = [np.dot(act, direction) for act in harmful_acts]
    harmless_proj = [np.dot(act, direction) for act in harmless_acts]

    harm_mean = np.mean(harmful_proj)
    harmless_mean = np.mean(harmless_proj)
    harm_std = np.std(harmful_proj)
    harmless_std = np.std(harmless_proj)
    separation = harm_mean - harmless_mean

    # Get overlap count from our analysis
    overlap = [r for r in layer_analysis if r['layer'] == layer_num][0]['overlap_count']

    # Plot histogram
    ax.hist(harmful_proj, bins=25, alpha=0.6, color='red', label='Harmful', density=True)
    ax.hist(harmless_proj, bins=25, alpha=0.6, color='blue', label='Harmless', density=True)
    ax.axvline(harm_mean, color='red', linestyle='--', linewidth=2)
    ax.axvline(harmless_mean, color='blue', linestyle='--', linewidth=2)

    # Title with key metrics
    ax.set_title(f'Layer {layer_num}\n'
                 f'Sep={separation:.1f}, Overlap={overlap}, '
                 f'H-std={harm_std:.2f}',
                 fontsize=11, fontweight='bold')

    ax.set_xlabel('Projection Value', fontsize=10)
    ax.set_ylabel('Density', fontsize=10)
    ax.legend(fontsize=9, loc='upper right')
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('results/validation/progressive_distributions.png', dpi=300, bbox_inches='tight')
print("✓ Saved: results/validation/progressive_distributions.png")
plt.show()

print("\nKey observations visible in plot:")
print("  - Layer 0: Small separation, high overlap (5)")
print("  - Layer 9: First zero overlap - categorical decision emerges")
print("  - Layer 18: Peak discrimination with wide variance")
print("  - Layer 27: Separation maintained but increased variance")