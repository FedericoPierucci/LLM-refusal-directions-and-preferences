{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNObeQT/KgW1jVa8RYXJ+Qu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FedericoPierucci/LLM-refusal-directions-and-preferences/blob/main/Experiment_2_Validation_Qwen7b_Instruct.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "cpAnN-h2Iqvv",
        "outputId": "b09b81ee-fc9e-4214-d97d-6d66f34139e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/LLM-refusal-directions-and-preferences\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1366202159.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -q -r requirements.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_lock_unlock_module\u001b[0;34m(name)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "EXPERIMENT X: Direction Validation (Parametrized)\n",
        "================================================\n",
        "Run the same pipeline on another Qwen size (default: 7B Instruct)\n",
        "\n",
        "Outputs (under results/ and data/):\n",
        "- layer_analysis_{TAG}.png\n",
        "- projection_distributions_{TAG}.png\n",
        "- progressive_distributions_{TAG}.png\n",
        "- variance_by_layer_{TAG}.csv\n",
        "- per_prompt_projections_lastlayer_{TAG}.csv\n",
        "- validated_directions_{TAG}.pkl\n",
        "\"\"\"\n",
        "\n",
        "# --- Config ---\n",
        "model_name = \"Qwen/Qwen2.5-7B-Instruct\"  # <-- change to any Qwen2.5-*B-Instruct\n",
        "TAG = \"Qwen7b\"                           # short tag for filenames\n",
        "\n",
        "# --- Setup (same as before) ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/LLM-refusal-directions-and-preferences\n",
        "\n",
        "import sys, os, pickle\n",
        "sys.path.append('/content/drive/MyDrive/LLM-refusal-directions-and-preferences')\n",
        "\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "from scipy.stats import ttest_ind\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.makedirs(\"results/validation\", exist_ok=True)\n",
        "os.makedirs(\"data/directions\", exist_ok=True)\n",
        "\n",
        "print(\"✓ All imports successful\")\n",
        "print(f\"✓ CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "# --- Load model ---\n",
        "print(f\"Loading {model_name}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name, torch_dtype=torch.float16, device_map=\"auto\"\n",
        ")\n",
        "n_layers = len(model.model.layers)\n",
        "hidden_size = model.config.hidden_size\n",
        "print(f\"✓ Model loaded | Layers: {n_layers} | Hidden size: {hidden_size}\")\n",
        "\n",
        "# --- Datasets (same cap as before; adjust if needed) ---\n",
        "print(\"Loading datasets...\")\n",
        "harmful_ds = load_dataset('mlabonne/harmful_behaviors')\n",
        "harmful_prompts = harmful_ds['train']['text'][:256]\n",
        "harmless_ds = load_dataset('mlabonne/harmless_alpaca')\n",
        "harmless_prompts = harmless_ds['train']['text'][:256]\n",
        "print(f\"✓ Loaded {len(harmful_prompts)} harmful / {len(harmless_prompts)} harmless\")\n",
        "\n",
        "# --- Activation helper (same logic) ---\n",
        "def get_activation(prompt, model, tokenizer, layer_idx):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    formatted = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer(formatted, return_tensors=\"pt\", truncation=True, max_length=512).to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_hidden_states=True)\n",
        "    last_pos = inputs['input_ids'].shape[1] - 1\n",
        "    # +1: hidden_states[0] is embeddings; layer i output is at i+1\n",
        "    return outputs.hidden_states[layer_idx + 1][0, last_pos, :].float().cpu().numpy()\n",
        "\n",
        "# --- Compute directions for all layers ---\n",
        "print(\"=\"*60)\n",
        "print(\"COMPUTING REFUSAL DIRECTIONS FOR ALL LAYERS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Processing {len(harmful_prompts)} + {len(harmless_prompts)} prompts across {n_layers} layers\\n\")\n",
        "\n",
        "all_directions = []\n",
        "for layer_idx in range(n_layers):\n",
        "    print(f\"Processing layer {layer_idx}/{n_layers-1}...\", end=\" \")\n",
        "    harmful_acts, harmless_acts = [], []\n",
        "\n",
        "    for prompt in tqdm(harmful_prompts, desc=f\"Layer {layer_idx} harmful\", leave=False):\n",
        "        harmful_acts.append(get_activation(prompt, model, tokenizer, layer_idx))\n",
        "    for prompt in tqdm(harmless_prompts, desc=f\"Layer {layer_idx} harmless\", leave=False):\n",
        "        harmless_acts.append(get_activation(prompt, model, tokenizer, layer_idx))\n",
        "\n",
        "    harmful_mean = np.array(harmful_acts).mean(axis=0)\n",
        "    harmless_mean = np.array(harmless_acts).mean(axis=0)\n",
        "    direction = harmful_mean - harmless_mean\n",
        "    magnitude = float(np.linalg.norm(direction))\n",
        "    direction_norm = direction / (magnitude if magnitude > 0 else 1.0)\n",
        "\n",
        "    all_directions.append({\n",
        "        \"layer\": layer_idx,\n",
        "        \"direction\": direction_norm,\n",
        "        \"magnitude\": magnitude,\n",
        "        \"harmful_acts\": harmful_acts,\n",
        "        \"harmless_acts\": harmless_acts\n",
        "    })\n",
        "    print(f\"✓ magnitude: {magnitude:.3f}\")\n",
        "\n",
        "print(f\"\\n✓ Computed directions for all {n_layers} layers\")\n",
        "\n",
        "# --- Statistical validation (same) ---\n",
        "print(\"=\"*60)\n",
        "print(\"STATISTICAL VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "validation_results = []\n",
        "for d in all_directions:\n",
        "    direction = d[\"direction\"]\n",
        "    harmful_proj = [np.dot(a, direction) for a in d[\"harmful_acts\"]]\n",
        "    harmless_proj = [np.dot(a, direction) for a in d[\"harmless_acts\"]]\n",
        "    t_stat, p_val = ttest_ind(harmful_proj, harmless_proj)\n",
        "    mean_diff = np.mean(harmful_proj) - np.mean(harmless_proj)\n",
        "    pooled_std = np.sqrt((np.std(harmful_proj)**2 + np.std(harmless_proj)**2) / 2)\n",
        "    cohens_d = float(mean_diff / pooled_std) if pooled_std > 0 else 0.0\n",
        "    validation_results.append({\n",
        "        \"layer\": d[\"layer\"],\n",
        "        \"magnitude\": d[\"magnitude\"],\n",
        "        \"harmful_mean_proj\": float(np.mean(harmful_proj)),\n",
        "        \"harmless_mean_proj\": float(np.mean(harmless_proj)),\n",
        "        \"t_statistic\": float(t_stat),\n",
        "        \"p_value\": float(p_val),\n",
        "        \"cohens_d\": cohens_d,\n",
        "        \"valid\": (p_val < 0.01 and abs(cohens_d) > 0.5)\n",
        "    })\n",
        "\n",
        "# --- Sort and print brief summary ---\n",
        "sorted_results = sorted(validation_results, key=lambda x: abs(x[\"cohens_d\"]), reverse=True)\n",
        "valid_layers = [r for r in validation_results if r[\"valid\"]]\n",
        "print(f\"\\n✓ Valid directions: {len(valid_layers)}/{n_layers}\")\n",
        "print(\"Top 10 by |Cohen d|:\")\n",
        "for r in sorted_results[:10]:\n",
        "    print(f\"Layer {r['layer']:>2} | mag={r['magnitude']:.2f} | d={r['cohens_d']:.2f} | p={r['p_value']:.2e} | {'✓' if r['valid'] else '✗'}\")\n",
        "\n",
        "# --- Plots (saved with TAG) ---\n",
        "layers = [r[\"layer\"] for r in validation_results]\n",
        "magnitudes = [r[\"magnitude\"] for r in validation_results]\n",
        "cohens_d = [r[\"cohens_d\"] for r in validation_results]\n",
        "p_values = [-np.log10(r[\"p_value\"]) if r[\"p_value\"] > 0 else 350 for r in validation_results]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "axes[0].plot(layers, magnitudes, 'o-', linewidth=2)\n",
        "axes[0].set_xlabel('Layer'); axes[0].set_ylabel('Direction Magnitude'); axes[0].set_title('Separation Distance'); axes[0].grid(True, alpha=0.3)\n",
        "axes[1].plot(layers, cohens_d, 'o-', linewidth=2)\n",
        "axes[1].axhline(0.5, color='r', linestyle='--', label='d=0.5'); axes[1].legend()\n",
        "axes[1].set_xlabel('Layer'); axes[1].set_ylabel(\"Cohen's d\"); axes[1].set_title('Effect Size'); axes[1].grid(True, alpha=0.3)\n",
        "axes[2].plot(layers, p_values, 'o-', linewidth=2)\n",
        "axes[2].axhline(-np.log10(0.01), color='r', linestyle='--', label='p=0.01'); axes[2].legend()\n",
        "axes[2].set_xlabel('Layer'); axes[2].set_ylabel('-log10(p)'); axes[2].set_title('Significance'); axes[2].grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'results/validation/layer_analysis_{TAG}.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# --- Variance analysis across layers (CSV) ---\n",
        "layer_analysis = []\n",
        "for d in tqdm(all_directions, desc=\"Variance pass\"):\n",
        "    direction = d[\"direction\"]\n",
        "    harmful_proj = [np.dot(a, direction) for a in d[\"harmful_acts\"]]\n",
        "    harmless_proj = [np.dot(a, direction) for a in d[\"harmless_acts\"]]\n",
        "    layer_analysis.append({\n",
        "        'layer': d['layer'],\n",
        "        'harmful_mean': float(np.mean(harmful_proj)),\n",
        "        'harmful_std': float(np.std(harmful_proj)),\n",
        "        'harmful_min': float(np.min(harmful_proj)),\n",
        "        'harmful_max': float(np.max(harmful_proj)),\n",
        "        'harmful_range': float(np.max(harmful_proj) - np.min(harmful_proj)),\n",
        "        'harmless_mean': float(np.mean(harmless_proj)),\n",
        "        'harmless_std': float(np.std(harmless_proj)),\n",
        "        'harmless_min': float(np.min(harmless_proj)),\n",
        "        'harmless_max': float(np.max(harmless_proj)),\n",
        "        'harmless_range': float(np.max(harmless_proj) - np.min(harmless_proj)),\n",
        "        'mean_separation': float(np.mean(harmful_proj) - np.mean(harmless_proj)),\n",
        "        'overlap_count': int(\n",
        "            len([p for p in harmful_proj if p < np.mean(harmless_proj)]) +\n",
        "            len([p for p in harmless_proj if p > np.mean(harmful_proj)])\n",
        "        ),\n",
        "    })\n",
        "df_variance = pd.DataFrame(layer_analysis)\n",
        "df_variance.to_csv(f'results/validation/variance_by_layer_{TAG}.csv', index=False)\n",
        "print(f\"✓ Saved: results/validation/variance_by_layer_{TAG}.csv\")\n",
        "\n",
        "# --- Save per-prompt projections at LAST LAYER (both splits) ---\n",
        "last_layer = n_layers - 1\n",
        "d_last = next(d for d in all_directions if d[\"layer\"] == last_layer)\n",
        "dir_last = d_last[\"direction\"]\n",
        "\n",
        "harm_last = [np.dot(a, dir_last) for a in d_last[\"harmful_acts\"]]\n",
        "harml_last = [np.dot(a, dir_last) for a in d_last[\"harmless_acts\"]]\n",
        "\n",
        "df_per_prompt = pd.DataFrame({\n",
        "    \"split\": ([\"harmful\"]*len(harm_last)) + ([\"harmless\"]*len(harml_last)),\n",
        "    \"prompt\": harmful_prompts + harmless_prompts,\n",
        "    \"projection_last_layer\": harm_last + harml_last\n",
        "})\n",
        "df_per_prompt.to_csv(f\"results/validation/per_prompt_projections_lastlayer_{TAG}.csv\", index=False)\n",
        "print(f\"✓ Saved: results/validation/per_prompt_projections_lastlayer_{TAG}.csv\")\n",
        "\n",
        "# --- Save directions + validation pickle ---\n",
        "save_data = {\n",
        "    \"model_name\": model_name,\n",
        "    \"n_layers\": n_layers,\n",
        "    \"directions\": all_directions,\n",
        "    \"validation_results\": validation_results\n",
        "}\n",
        "with open(f\"data/directions/validated_directions_{TAG}.pkl\", \"wb\") as f:\n",
        "    pickle.dump(save_data, f)\n",
        "print(f\"✓ Saved: data/directions/validated_directions_{TAG}.pkl\")\n",
        "\n",
        "# --- Optional: one more plot (distributions at a few key layers) ---\n",
        "key_layers = [0, max(1, n_layers//6), max(1, n_layers//3), max(1, n_layers//2),\n",
        "              max(1, (2*n_layers)//3), n_layers-3, n_layers-2, n_layers-1]\n",
        "key_layers = sorted(set([k for k in key_layers if 0 <= k < n_layers]))[:8]\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "fig.suptitle(f'Projection Distributions Across Key Layers ({TAG})', fontsize=18, fontweight='bold')\n",
        "for idx, layer_num in enumerate(key_layers):\n",
        "    row, col = idx // 4, idx % 4\n",
        "    ax = axes[row, col]\n",
        "    d = all_directions[layer_num]\n",
        "    direction = d['direction']\n",
        "    harmful_proj = [np.dot(a, direction) for a in d['harmful_acts']]\n",
        "    harmless_proj = [np.dot(a, direction) for a in d['harmless_acts']]\n",
        "    harm_mean, harmless_mean = np.mean(harmful_proj), np.mean(harmless_proj)\n",
        "    harm_std, harmless_std = np.std(harmful_proj), np.std(harmless_proj)\n",
        "    separation = harm_mean - harmless_mean\n",
        "    overlap = len([p for p in harmful_proj if p < harmless_mean]) + len([p for p in harmless_proj if p > harm_mean])\n",
        "\n",
        "    ax.hist(harmful_proj, bins=25, alpha=0.6, density=True, label='Harmful')\n",
        "    ax.hist(harmless_proj, bins=25, alpha=0.6, density=True, label='Harmless')\n",
        "    ax.axvline(harm_mean, linestyle='--', linewidth=2)\n",
        "    ax.axvline(harmless_mean, linestyle='--', linewidth=2)\n",
        "    ax.set_title(f'Layer {layer_num} | Sep={separation:.1f} | Overlap={overlap} | H-std={harm_std:.2f}', fontsize=10, fontweight='bold')\n",
        "    ax.set_xlabel('Projection'); ax.set_ylabel('Density'); ax.grid(True, alpha=0.3)\n",
        "    ax.legend(fontsize=9, loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'results/validation/progressive_distributions_{TAG}.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDone.\")"
      ]
    }
  ]
}